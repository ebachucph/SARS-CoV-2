---
title: "Main"
author: "Emil Bach"
date: "2/1/2022"
output: github_document
---
# Insert publication title here
The following code runs the analysis used to find potential linear IgA and IgG in SARS-CoV-2, 8 other coronaviridae, and HCMV from high-density peptide microarray data. The results of the analyses and generated figures and tables are published under the DOI:

## System info
The analyses were run on:
  Model Name: MacBook Pro
  Model Identifier: MacBookPro16,1
  System Version: macOS 12.4 (21F79)
  Kernel Version: Darwin 21.5.0
  Processor Name: 8-Core Intel Core i9
  Processor Speed: 2,4 GHz
  Number of Processors: 1
  Total Number of Cores: 8
  L2 Cache (per Core): 256 KB
  L3 Cache: 16 MB
  Hyper-Threading Technology: Enabled
  Memory: 64 GB

## Requirements
### Z shell / Bash
To clean/filter, align, and translate the SARS-CoV-2 sequences from [Global Initiative on Sharing All Influenza Data (GISAID)](https://www.gisaid.org/) following libraries are needed:
 * [*Seqkit*](https://bioinf.shenwei.me/seqkit/) (version 2.2.0)
 * [*Nextalign*](https://docs.nextstrain.org/projects/nextclade/en/stable/user/nextalign-cli.html) (version 1.10.2)

### R libraries
 * *ape* (version 5.5)
 * *Biostrings* (version 2.60.1)
 * *broom* (version 0.7.9)
 * *colorspace* (version 2.0.2)
 * *data.table* (version 1.14.0)
 * *DECIPHER* (version 2.20.0)
 * *ggnetwork* (version 0.5.10)
 * *ggnewscale* (version 0.4.5)
 * *ggpubr* (version 0.4.0)
 * *ggrepel* (version 0.9.1)
 * *gridExtra* (version 2.3)
 * *igraph* (version 1.2.11)
 * *network* (version 1.17.11)
 * *parallel* (version 4.1.2)
 * *Peptides* (version 2.4.4)
 * *plyranges* (version 1.12.1)
 * *reshape2* (version 1.4.4)
 * *tidyverse* (version 1.3.1)
 * *boot* (verison 1.3.28)

## Data availability 
Peptide microarray data, peptide sequence metadata, and SARS-CoV-2 protein Shannon entropy are available from the following [source](https://datadryad.org/stash). SARS-CoV-2 DNA sequences used for alignment and translation for calculation of Shannon entropy are available at [GISAID](https://www.gisaid.org/).

## License
This script is published under a CCBY 0 license...

---

## SCRIPT BELOW
```{r setup, include=FALSE}
# Function to record runtime of chunks from https://bookdown.org/yihui/rmarkdown-cookbook/time-chunk.html
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- difftime(Sys.time(), now)
      # return a character string to show the time
      paste0("Time for chunk, ", options$label, ", to run: ", round(res, 2), " second(s).")
    }
  }
}))
knitr::opts_chunk$set(echo = TRUE, time_it = TRUE)
# Don't evaluate chunks when running
# knitr::opts_chunk$set(eval = FALSE)
```

## Loading libraries  
Code chunk below will load the libraries and local functions in ./docs/functions required to run the analysis.

```{r libraries, message=FALSE, warning=FALSE, results='hide'}
# Load libraries
library(ape, quietly = T, warn.conflicts = F) #5.5
library(Biostrings, quietly = T, warn.conflicts = F) #2.60.1
library(broom, quietly = T, warn.conflicts = F) #0.7.9
library(colorspace, quietly = T, warn.conflicts = F) #2.0.2
library(data.table, quietly = T, warn.conflicts = F) #1.14.0
library(DECIPHER, quietly = T, warn.conflicts = F) #2.20.0
library(ggnetwork, quietly = T, warn.conflicts = F) #0.5.10
library(ggnewscale, quietly = T, warn.conflicts = F) #0.4.5
library(ggpubr, quietly = T, warn.conflicts = F) #0.4.0
library(ggrepel, quietly = T, warn.conflicts = F) #0.9.1
library(gridExtra, quietly = T, warn.conflicts = F) #2.3
library(igraph, quietly = T, warn.conflicts = F) #1.2.11
library(network, quietly = T, warn.conflicts = F) #1.17.11
library(parallel, quietly = T, warn.conflicts = F) #4.1.2
library(Peptides, quietly = T, warn.conflicts = F) #2.4.4
library(plyranges, quietly = T, warn.conflicts = F) #1.12.1
library(reshape2, quietly = T, warn.conflicts = F) #1.4.4
library(tidyverse, quietly = T, warn.conflicts = F) #1.3.1
library(boot, quietly = T, warn.conflicts = F) #1.3.28

# Source scripts in ./docs/functions
for(f in list.files("./docs/functions", full.names = T)){
  if(!is_empty(f)) {
    #writeLines(paste0("Sourcing: ", f,"\n"))
    tryCatch(suppressMessages(source(f)),
             finally = {next})
  }
}
 
```

## Loading data  
This chunk loads the raw high-density peptide microarray data from the ./data/raw folder.
```{r loading-data, message=FALSE, warning=FALSE, results='hide'}
# Load raw data and split into lists based on serum pool and Ig-type
data.list <- fread("./data/raw/SARS2 all raw.txt") %>% 
  list(.) %>% 
  rep(., 4) %>% 
  setNames(1:length(.)) %>% 
  map2(., names(.), ~.x %>% dplyr::select(c(1:5, as.integer(.y)+5))) %>% 
  setNames(unlist(map(., ~names(.x)[ncol(.x)]))) %>% 
  map2(., names(.), ~.x %>% dplyr::rename(Signal := !!.y))
```

This chunk loads the peptide sequence metadata together with the fasta files used to generate the peptide sequences.
```{r loading-metadata, message=FALSE, warning=FALSE, results='hide'}
# Load metadata
complete.map <- fread("./data/Protein complete map.txt")

# Fasta files used for generating the peptide microarray design
## Fasta files are loaded using the Biostrings package and combined into a single object
fasta <- lapply(list.files("./data/fasta", "\\.fasta$", full.names = T, ignore.case = T), readBStringSet) %>%
  do.call("c", .) %>% 
  setNames(str_extract(names(.), "^.*?(?= )"))
```

This chunk cleans the microarray day by changing missing signal value encoding from -1 to NA. Column names are changed to contain only lower letters.
```{r clean-data, message=FALSE, warning=FALSE, results='hide'}
# Clean the microarray data
## Keep only relevant columns for analysis, rename to match 'complete.map', and join with 'complete.map'
data.list.clean <- data.list %>% 
  map2(., names(.), ~{
    .x %>% 
      dplyr::select(Coresequence, Signal, Group) %>% 
      setNames(., tolower(names(.))) %>% 
      .[, signal := ifelse(signal < 0, NA, signal)] %>% 
      mutate(name = .y)
  })

# Save cleaned data in ./data/clean
if(!dir.exists("./data/clean")) { dir.create("./data/clean") }

data.list.clean %>% 
  map2(., names(.), ~fwrite(.x, file.path("./data/clean", paste0(.y, ".txt"))))

# Remove data to clear space
rm(list = c("data.list"))

```

This chunk summarizes signal values from the peptide replicates by estimating their arithmetic mean (removing replicates with missing values). Summarized signal values are then standardized by subtracting the median of the random background peptides, and the p-value of each peptide is estimated using the ECDF of the random background peptides.
```{r data-normalization, message=FALSE, warning=FALSE, results='hide'}
# Load clean data
if(!"data.list.clean" %in% ls()){
  data.list.clean <- list()
  append2list(data.list.clean, list.files(path = "./data/clean", full.names = T), fread, key = "coresequence")
  data.list.clean <- setNames(data.list.clean, str_remove(basename(names(data.list.clean)), ".txt"))
}

# Make folder ./data/analysed to save analysed data
if(!dir.exists("./data/norm")) { dir.create("./data/norm") }

# Normalize the data and calculate probability of being in background ECDF
### Resulting value for each peptide will be called 'p.value'
data.list.clean.norm <- data.list.clean %>% 
  mclapply(., function(x) {
    x[,.(
      mean_signal = mean(signal, na.rm = T),
      sd_signal = sd(signal, na.rm = T),
      n_pep = sum(!is.na(signal)),
      N = .N,
      group = unique_combine(group),
      name = unique(name)
    ), keyby = .(coresequence)
    ] %>% 
      filter(complete.cases(.)) %>% 
      .[, norm_signal := mean_signal - median(mean_signal[str_detect(group, "random")], na.rm = T)] %>%
      .[, norm_signal := ifelse(norm_signal < 0, 0, norm_signal) + 1] %>%
      .[, cv_signal := sd_signal/mean_signal] %>%
      .[, p.value := my_ecdf(norm_signal[str_detect(group, "random")])(norm_signal)] %>% 
      .[, scale_signal := norm_signal/max(norm_signal)]
  },
  mc.cores = length(data.list.clean))

# Write to ./data/norm
data.list.clean.norm %>%
  map2(., names(.), ~fwrite(.x, file.path("./data/norm", paste0(.y,".txt"))))

# Remove data to clear space
rm(list = c("data.list.clean"))

```

This chunk performs the response peptide analysis by combining the p-values of overlapping peptides with *Fisher's Combined Probability test*.
```{r data-analysis, message=FALSE, warning=FALSE, results='hide'}
# Load normalized data
if(!"data.list.clean.norm" %in% ls()){
  data.list.clean.norm <- list()
  append2list(data.list.clean.norm, list.files(path = "./data/norm", full.names = T), fread, key = "coresequence")
  data.list.clean.norm <- setNames(data.list.clean.norm, str_remove(basename(names(data.list.clean.norm)), ".txt"))
}

# Make folder ./data/analysed to save analysed data
if(!dir.exists("./data/analysed")) { dir.create("./data/analysed") }

# Perform analysis with Fisher's Combined Probability test on P(in background) for peptides overlapping >= 11 in parent protein
## Resulting value for each peptide will be called 'q.value' 
data.list.clean.norm.analysed <- mclapply(data.list.clean.norm, function(dt){
    merge(complete.map, dt, by = "coresequence")[, `:=`(
      seqnames = prot_name,
      width = nchar(coresequence),
      end = NULL
    )] %>% 
      .[, overlap_windows(.SD, 11, "p.value", "q.value", fishers_method), by = .(prot_name)]
  }, mc.cores = length(data.list.clean.norm))

# Write to ./data/analysed
data.list.clean.norm.analysed %>%
  map2(., names(.), ~fwrite(.x, file.path("./data/analysed", paste0(.y,".txt"))))

# Remove data to clear space
rm(list = c("data.list.clean.norm"))

```

## Calculate Shannon Entropy
### Get high quality sequences from GISAID
```{r filter-gisaid}
# Load GISAID metadata
gisaid_meta <- fread("./data/gisaid/metadata_tsv_2022_02_21/metadata.tsv", sep = "\t", nThread = 8)

# Filter on relevant columns
gisaid_meta_f <- gisaid_meta %>% 
  filter(`Is complete?`) %>% 
  filter(`Is high coverage?`) %>% 
  filter(is.na(`Is low coverage?`)) %>% 
  filter(Host == "Human") %>% 
  filter(is.na(`Is reference?`)) %>% 
  filter(Type == "betacoronavirus")

## Get the reference sequence in the GISAID database
gisaid_meta_ref <- gisaid_meta %>% filter(`Is reference?`)

# Write the filtered metadata to a text file to filter fasta with seqkit
gisaid_meta_f %>%
  distinct(`Virus name`, `Collection date`, `Submission date`) %>% 
  unite(., "name", 1:3, sep = "|") %>% 
  fwrite(., "./data/gisaid/keep_list.txt", col.names = F)

# Write the reference sequence from Wuhan to a separate text file to filter with seqkit
gisaid_meta_ref %>%
  distinct(`Virus name`, `Collection date`, `Submission date`) %>% 
  unite(., "name", 1:3, sep = "|") %>% 
  fwrite(., "./data/gisaid/reference.txt", col.names = F)
```

### Use seqkit to filter fasta files
Provide the path for the gisaid folder
```{r set-bash-home}
Sys.setenv(gisaid = "./data/gisaid")
```

Extract DNA sequences from the tar file.
```{zsh gisaid-extract-tar, engine.opts='-i', results=FALSE}
tar -xf $gisaid/*.xz -C $gisaid

```

Extract the reference sequence and keep in separate fasta.
Filter gisaid sequences with fasta headers in keep_list.txt
Remove duplicated sequences in sequences_f.fasta
Remove duplicated sequences in sequences_f.fasta
```{zsh gisaid-filter, engine.opts='-i', results=FALSE}
seqkit grep -n -j 8 -f $gisaid/reference.txt $gisaid/sequences.fasta -o $gisaid/reference.fasta &&

seqkit grep -n -j 8 -f $gisaid/keep_list.txt $gisaid/sequences.fasta -o $gisaid/sequences_f.fasta &&

touch $gisaid/duplicated_nucleotide.txt &&
seqkit rmdup -s -j 8 -o $gisaid/sequences_f_clean.fasta $gisaid/sequences_f.fasta &> $gisaid/duplicated_nucleotide.txt &&

rm $gisaid/sequences.fasta $gisaid/sequences_f.fasta
```

Align GISAID sequences
```{zsh align-gisaid, engine.opts='-i', results=FALSE}
mkdir -p $gisaid/output > /dev/null 2>&1 &&
nextalign -i $gisaid/sequences_f_clean.fasta \
-j 12 \
--include-reference \
-g ORF1a,ORF1b,S,ORF3a,ORF3b,E,M,ORF6,ORF7a,ORF7b,ORF8,N,ORF9a,ORF9b \
-m $gisaid/nextalign_sars2_genemap.gff \
--nuc-mismatches-allowed 6 \
-r $gisaid/reference.fasta \
-o $gisaid/output/sequences_aligned.fasta \
-d $gisaid/output &> $gisaid/output/unaligned_sequences.txt
```

Remove stop codon letter (*) from end of sequence, replace gaps with X, remove duplicate protein sequences, and write to new fasta file.
```{zsh protein-cleanup, engine.opts='-i', results=FALSE}
touch $gisaid/duplicated_proteins.txt
for file in $gisaid/output/*gene*(.); 
do
	g=${file##*gene.}
	p=$file:h
	echo "$g"
	seqkit replace -s -j 8 -p "\*" -r "" $file | seqkit replace -s -j 8 -p "-" -r "X" -o "$p/../protein/$g"
	seqkit rmdup -s -j 8 -o "$p/../unique/$g" "$p/../protein/$g"
done &> $gisaid/duplicated_proteins.txt

```

Filter the protein sequences for sequences with length equal to reference protein and remove proteins with > 5% X.
```{r filter-proteins, message=FALSE, warning=FALSE}
# Get fasta file paths
aligns <- list.files("./data/gisaid/unique", pattern = "fasta", full.names = T)

# Check if out dirs exist, otherwise create them
dirs <- c("./data/gisaid/standard")
for (d in dirs) {
  if(!dir.exists(d)) dir.create(d)
}

# Data frame to capture lengths
std_f_lengths <- data.frame(gene = character(0), Count = integer(0))

# Filter the protein sequences for standard length and X freq < 0.05
for(fs in aligns){
  # Show progress
  # print(paste0("Running: ", fs))
  cds <- readBStringSet(fs)
  
  # Check distribution of lengths and keep the most common length as standard
  seq_lengths <- lengths(cds)
  seq_lengths_dist <- table(seq_lengths)
  
  nonstd <- cds[seq_lengths != as.numeric(names(which.max(seq_lengths_dist)))]
  std <- cds[seq_lengths == as.numeric(names(which.max(seq_lengths_dist)))]
  
  # Check X frequency in each sequence
  std_f <- std[as.vector(letterFrequency(std, "X", as.prob = T) <= 0.05)]
  
  std_f_lengths <- data.frame(gene = str_extract(basename(fs), "^.*?(?=\\.)"),
                              Count = length(std_f)) %>% 
    rbind(std_f_lengths, .)
  
  # Write the standard and filtered sequences to new fasta
  writeXStringSet(std_f, filepath = file.path("./data/gisaid/standard", basename(fs)), format = "fasta")
}

# Save count data frame
fwrite(std_f_lengths, "./data/std_f_lengths.txt")
```

Find common denominator bootstrap set size between all proteins (or set size closest to)
```{r bootstrap-sets, message=FALSE, warning=FALSE}
# Reload std_f_lengths if not in environment
if(!"std_f_lengths" %in% ls()) {
  std_f_lengths <- fread("./data/std_f_lengths.txt")
}

# Initiate with set size vector from floor(10% of min set size) : floor(50% of min set size)
set_sizes <- seq(floor(min(std_f_lengths$Count)/10), floor(min(std_f_lengths$Count)/2))

# Find difference between float number of protein / set size and same fraction but rounded to closest integer
set_dif_mat <- map2(std_f_lengths$Count, std_f_lengths$gene, ~{
  frac <- .x / set_sizes
  int <- round(.x / set_sizes)
  set_diff <- abs(frac-int)
  matrix(set_diff, nrow = 1)
  }) %>%
  do.call(rbind, .)

# Find set size with the smallest column sum of differences (across all proteins n = 14)
opt_size <- set_sizes[which.min(colSums(set_dif_mat))]

# Find the integer closest to the optimal split for each protein
set.seed(123)
std_f_lengths <- std_f_lengths %>%
  mutate(chunks = round(Count / opt_size)) %>%
  mutate(chunks_idx = map2(Count, chunks, ~split_n(sample(seq(.x), size = .x), .y))) %>%
  mutate(size_min = unlist(map(chunks_idx, ~min(lengths(.x)))),
         size_max = unlist(map(chunks_idx, ~max(lengths(.x))))) %>% 
  as.data.table(.)

```

Calculate the Shannon entropy.
```{r calculate-shannon-entropy, message=FALSE, warning=FALSE}
# Check if out dirs exist, otherwise create them
dirs <- c("./data/ds_entropy", "./data/ds_entropy_x")
for (d in dirs) {
  if(!dir.exists(d)) dir.create(d)
}

# Load filtered fasta files
fastas <- list.files("./data/gisaid/standard", full.names = T)

# Calculate shannon entropy on chunks and combine by taking mean of each AA in each position
VERBOSE = F # Keep temporary folders?
for (fs in fastas) {
  print(paste0("Running: ", fs))
  # Read the fasta file
  cds <- readBStringSet(fs)
  
  # Split the fasta file into the chunks calculated in std_f_lengths
  current_gene <-  str_extract(basename(fs), ".*?(?=\\.)")
  chunks <- std_f_lengths[gene == current_gene, chunks]
  
  # Scramble and then split the protein sequences in chunks
  set.seed(123) # For reproducibility
  cds_idx <- sample(1:length(cds), length(cds))

  cds_split <- split_n(cds_idx, chunks) %>%
    map(., ~cds[.x])

  # Make temporary directory to write amino acid position count matrices
  tdir <- tempfile(paste0(current_gene, "_"), ".")
  dir.create(tdir)
  
  # Wrap everything in tryCatch to ensure removal of temporary dirs and files
  suppressMessages({
    tryCatch(expr = {
      # Count AA occurences in each position of protein with X as ambigous (write to "tdir")
      cds_split %>% 
        map2(., names(.), function(std, i){
          seq(unique(lengths(std))) %>% 
            split_n(., 8) %>% 
            mclapply(., function(x){
              map(x, ~{
                extractAt(std, IRanges(.x, width = 1)) %>% 
                  unlist() %>% 
                  as.vector(.) %>% 
                  table(factor(., levels = c(AA_STANDARD, "X"), ordered = T)) %>% 
                  colSums(.) %>% 
                  matrix(., ncol = 1, dimnames = list(names(.), .x))
              }) %>% 
                do.call("cbind", .)
            }, mc.cores = length(.)) %>% 
            do.call("cbind", .) %>% 
            .[, order(as.integer(colnames(.)))] %>% 
            fwrite(., tempfile("counts", tdir, ".txt"), col.names = F)
        })
      
      # Re-read count matrices and get mean counts per AA and position
      position_counts <- list.files(tdir, full.names = T) %>% 
        map(., ~fread(.x) %>% as.matrix(.)) %>% 
        Reduce("+", .)/length(cds_split)
      
      # Calculate position entropy
      position_freqs <- position_counts %>% 
        .[-nrow(.), 1:ncol(.), drop = F] %>% 
        apply(., 2,function(x) x/sum(x))
      position_entropy <- apply(position_freqs, 2, function(x) -sum(x * log2(x), na.rm = T))
      
      # Write gene-wise entropy to separate files
      as.data.frame(position_entropy) %>%
        rownames_to_column(., "position") %>%
        fwrite(., paste0("./data/ds_entropy/", str_extract(basename(fs), "^.*?(?=\\.)"), ".txt"))
      
      # Calculate position entropy with X
      position_freqs <- apply(position_counts, 2,function(x) x/sum(x))
      position_entropy <- apply(position_freqs, 2, function(x) -sum(x * log2(x), na.rm = T))
      
      # Write gene-wise entropy to separate files
      as.data.frame(position_entropy) %>%
        rownames_to_column(., "position") %>%
        fwrite(., paste0("./data/ds_entropy_x/", str_extract(basename(fs), "^.*?(?=\\.)"), ".txt"))
    }, 
    finally = {if(!VERBOSE){ unlink(tdir, T) }}
    )
  })
}

```

---

## Figures/tables
Set figure parameters according to journal guidelines
```{r figure-settings, message=FALSE, warning=FALSE}
# Set figure widths according to journal guidelines
## 1 column -> 75 mm
width1 <- 75

## 2 columns -> 15 mm
width2 <- 150

## Figure text -> 8 pt
text_size <- 8
```


### Pre-analysis table
Generate tables and figures of peptide sequences and their signals prior to analysis.
```{r reload-data, message=FALSE, warning=FALSE}
# Load data
data.clean.norm <- list.files("./data/norm", full.names = T) %>% 
  map(., fread) %>% 
  rbindlist(.) %>% 
  filter(complete.cases(.)) %>% 
  filter(!str_detect(group, "UNUSED|MARKER|EMPTY|CONTROL")) %>% # Remove irrelevant fields
  mutate(pep_group = ifelse(str_detect(group, "random"), "Random", "Test"), # Rename peptide groups
         patient_group = str_extract(name, "^.*?(?= Ig)"), # Make patient group
         ig_type = str_extract(name, "(?<= )Ig.$")) # Assign Ig-type

```

Table 1:
```{r design-count, message=FALSE, warning=FALSE}
# Count the number of unique peptide sequences from each organism
design_count <- complete.map %>% 
  filter(complete.cases(.)) %>% 
  mutate(table_org = paste0(organism, " (", org,")")) %>% 
  distinct(coresequence, table_org) %>% 
  rbind(., data.frame(coresequence = unique(.$coresequence), table_org = "Total")) %>% 
  count(table_org)

# Write table to txt
fwrite(design_count, "./images/publication/design_count.txt", sep = "\t")
rm(list = "design_count")
```

### Post-analysis figures/tables
Generate tables and figures of peptide sequences and their signals after analysis and detection of response peptides.

Reload post-analysis data.
```{r reload-analysed-data, message=FALSE, warning=FALSE}
# Load analysed data
data.analysed <- list.files("./data/analysed", full.names = T) %>% 
  map(., fread) %>% 
  rbindlist(.) %>% 
  filter(!is.na(prot_name)) %>% 
  mutate(patient_group = str_extract(name, "^.*?(?= Ig)"), # Make patient group
         ig_type = str_extract(name, "(?<= )Ig.$")) %>%  # Assign Ig-type
  mutate(Response = q.value <= 0.001 & scale_signal >= 0.2)
```

Figure 1:
```{r peptide-signal-distributions, message=FALSE, warning=FALSE}
# Combine pre- and post-analysis data and plot distributions of different peptide groups
f1 <- list(data.clean.norm %>% filter(pep_group == "Random"), data.analysed) %>% 
  rbindlist(fill = T, use.names = T) %>% 
  mutate(pep_group = case_when(Response ~ "High-fidelity",
                               !Response ~ "Low-fidelity",
                               is.na(Response) ~ "Negative control")) %>% 
    group_by(pep_group, patient_group, ig_type) %>% 
  mutate(outlier = log2(norm_signal) > quantile(log2(norm_signal), 0.75) + 1.5 * IQR(log2(norm_signal))) %>%
  group_modify(~ add_row(.x,.before=0)) %>% # Add empty row for jitter alignment
  mutate(outlier = ifelse(is.na(outlier), T, outlier)) %>% 
  ungroup() %>% 
  ggplot(., aes(x = ig_type, y = norm_signal, fill = factor(pep_group))) +
  geom_boxplot(outlier.shape = NA, color = "grey75", lwd = 0.5, fatten = 0.9) +
  geom_point(data = function(x) dplyr::filter_(x, ~ outlier),
             position = position_jitterdodge(jitter.width = 0.4), shape = 21,
             color = "grey50", alpha = 0.3, size = 0.5) +
  scale_y_continuous(trans = "log2", limits = c(1, 256), breaks = 2^(0:8)) +
  scale_fill_manual(values = c("High-fidelity" = "orange", 
                               "Low-fidelity" = "grey50", 
                               "Negative control" = "black")) +
  facet_wrap(~patient_group) +
  labs(x = "Ig-type", y = "Standardized Signal", fill = "Peptide Group") +
  theme_pubr(base_size = text_size) + 
  theme(panel.grid.major.y = element_line(),
        strip.text = element_text(face = "bold"),
        axis.title.x = element_blank(),
        axis.text.x = element_text(face = "bold"),
        axis.title.y = element_text(face = "bold"),
        legend.title = element_text(face = "bold"))

# Save plot
ggsave("./images/publication/figure1.svg", f1, width = width2, height = width1, units = "mm", device = "svg")

# Clear space in environment
# rm(list = c("data.clean.norm", "f1"))
```


Table 2:
```{r response-count, message=FALSE, warning=FALSE}
# Get distinct responses across patient_group:ig_type
distincts <- data.analysed %>% 
  filter(Response) %>% 
  mutate(name = paste(ig_type, patient_group)) %>% 
  distinct(name, org, coresequence)

# Count distinct responses per organism grouped by ig_type:patient_group
distincts_org.name <- distincts %>% 
  count(org, name) %>% 
  pivot_wider(., id_cols = "org", names_from = "name", values_from = "n") %>% 
  rbind(., distincts %>% 
  distinct(name, coresequence) %>% 
  count(name) %>% 
  mutate(org = "Total") %>% 
  pivot_wider(., id_cols = "org", names_from = "name", values_from = "n"))

# Count distinct responses per organism
distincts_org <- distincts %>% 
  distinct(org, coresequence) %>% 
  count(org) %>% 
  dplyr::rename("All" = "n") %>% 
  rbind(., distincts %>% 
  distinct(coresequence) %>% 
  count() %>% 
  mutate(org = "Total") %>% 
  dplyr::rename("All" = "n"))

# Combine the counts
peptide_response_table <- cbind(distincts_org.name, distincts_org)

# Write the table
fwrite(peptide_response_table, "./images/publication/peptide_response_table.txt", sep = "\t")

rm(list = str_subset(ls(), "distincts|peptide_response_table"))
```

### SARS-CoV-2 proteome-wide response overview
Load protein positional Shannon entropy calculated from alignment of GISAID SARS-CoV-2 DNA sequences.
```{r load-entropy, message=FALSE, warning=FALSE}
# Load entropy data
entropy <- list.files("./data/ds_entropy_x", full.names = T) %>% 
  map(., ~fread(.x) %>% mutate(gene_abbr = str_replace(basename(.x), "\\.txt", ""))) %>% 
  rbindlist(.) %>% 
  split(., str_detect(.$gene_abbr, "ORF1")) %>% 
  map2(., names(.), ~if(.y) {
    .x %>% 
      mutate(gene_abbr = "ORF1ab",
             position = 1:nrow(.)) %>% 
      rbind(.x %>% filter(gene_abbr == "ORF1a"), .)
  } else {
    .x
  }) %>% 
  rbindlist(.)

```

Prepare post-analysis data for the layout used in Figure 5 and Supplementary figure 2
```{r prepare-protein-data, message=FALSE, warning=FALSE}
# Set order of proteins based on start position of gene in SARS-CoV-2 genome
protein_order <- c("ORF1a", "ORF1ab", "S", "ORF3a", "ORF3b", "E", "M", "ORF6", "ORF7a", "ORF7b", "ORF8", "N", "ORF9a", "ORF9b")

# Get GISAID like names from UniProt
sars2_feats <- complete.map %>% 
  distinct(org, prot_name) %>% 
  mutate(UniProt = str_extract(prot_name, "(?<=\\|).*?(?=\\|)")) %>% 
  filter(complete.cases(.)) %>% 
  filter(org == "SARS-CoV-2") %>% 
  mutate(gene_abbr = get_genename(UniProt))

# Fix names for polyproteins
sars2_feats$gene_abbr[1:2] <- c("ORF1a", "ORF1ab")

# Fix names for ORF9b->ORF9a and ORF9c->ORF9b
sars2_feats <- sars2_feats %>% 
  mutate(gene_abbr = unlist(gene_abbr)) %>% 
  mutate(gene_abbr = case_when(gene_abbr == "ORF9b" ~ "ORF9a",
                             gene_abbr == "ORF9c" ~ "ORF9b",
                             T ~ gene_abbr)) %>% 
  mutate(gene_abbr = factor(gene_abbr, levels = protein_order, ordered = T))

# Filter Entropy to keep only entries in sars2_feats
entropy <- entropy %>% 
  left_join(., sars2_feats, by = "gene_abbr") %>% 
  filter(complete.cases(.)) %>% 
  mutate(gene_abbr = factor(gene_abbr, levels = protein_order, ordered = T))

# Filter data.analysed with entries in sars2_feats
data.sars2 <- data.analysed %>% 
  filter(org == "SARS-CoV-2") %>% 
  left_join(., sars2_feats, by = intersect(names(sars2_feats), names(data.analysed))) %>% 
  filter(complete.cases(.)) %>% 
  mutate(gene_abbr = factor(gene_abbr, levels = protein_order, ordered = T))
```

Make Figure 5 and Supplementary figure 2.
```{r sars2-proteome-plot, message=FALSE, warning=FALSE}
# Set number of AA position per row
n_rows <- 2000 

# Add the relative position of each peptide
data.sars2.rel <- data.sars2 %>% 
  group_by(gene_abbr) %>% 
  summarise(Ends = max(end)) %>% 
  filter(complete.cases(.)) %>% 
  filter(gene_abbr != "ORF1a") %>% 
  mutate(rel_end = cumsum(Ends)) %>% 
  mutate(rel_start = (rel_end - Ends)) %>% 
  mutate(rel_start = ifelse(rel_start > 0, rel_start + 1, rel_start)) %>% 
  distinct(gene_abbr, rel_start) %>% 
  left_join(data.sars2, .) %>% 
  mutate(rel_start = rel_start + start) %>% 
  mutate(rel_end = rel_start + width - 1) %>% 
  filter(complete.cases(.)) %>% 
  arrange(gene_abbr, rel_start) %>% 
  dplyr::rename("start" = "rel_start", "end" = "rel_end", "pstart" = "start", "pend" = "end")

# Make row breaks based on desired number of AA per row in plot
sars_rel_ends <- distinct(data.sars2.rel, end) %>% 
  unlist(., use.names = F)
row_max <- ceiling(max(sars_rel_ends) / n_rows)
end_idx <- unlist(lapply(seq(n_rows, n_rows * row_max, n_rows), function(x) which.min(abs(sars_rel_ends - x))))
row_ends <- c(sars_rel_ends[end_idx])
row_starts <- c(1,row_ends[-length(row_ends)] + 1)
row_splits <- IRanges(row_starts, row_ends, names = seq(length(row_starts)))

# Add relative positions and row number to entropy data
entropy.rel <- entropy %>% 
  filter(gene_abbr != "ORF1a") %>% 
  arrange(gene_abbr) %>% 
  mutate(start = 1:nrow(.), end = 1:nrow(.)) %>% 
  as_iranges(.) %>% 
  mergeByOverlaps(., row_splits, type = "within") %>% 
  as.data.frame(.) %>% 
  dplyr::select(-contains(".."), -matches("start|end|width")) %>% 
  dplyr::rename("row" = matches("names")) %>% 
  mutate(all_position = 1:nrow(.)) %>% 
  split(., .$row) %>%
  map2(., names(.), ~if(nrow(.x) >= n_rows) .x else {
    as.data.table(.x) %>%
      rbind(., data.table(all_position = seq(max(.x$all_position)+1,
                                             min(.x$all_position)+(n_rows-1))),
            fill = T) %>% 
      mutate(row = as.numeric(.y))
  }) %>%
  rbindlist(.) %>%
  mutate(entropy_scale = 0.05 + position_entropy/log2(21),
         ymin = 0.05) %>% 
  rbind(., mutate(., entropy_scale = -1 * entropy_scale,
                  ymin = -0.05))

# Add row number to sars2 data and transform scaled signal to be up/down
plot_data <- data.sars2.rel %>% 
  dplyr::select(-seqnames) %>% 
  as_iranges(.) %>% 
  mergeByOverlaps(., row_splits, type = "within") %>% 
  as.data.frame(.) %>% 
  dplyr::rename("rel_start" = "..start", "rel_end" = "..end") %>% 
  dplyr::select(-contains(".."), -matches("\\.(start|end|width)")) %>% 
  dplyr::rename("row" = matches("names"), "start" = "pstart", "end" = "pend") %>% 
  mutate(plot_signal = scale_signal + 0.05) %>% 
  mutate(plot_signal = ifelse(str_detect(name, "Neg"), -1 * plot_signal, plot_signal),
         ymin = ifelse(str_detect(name, "Neg"), -0.05, 0.05))

# Make intervals for rectangles showing proteins
prot_rect <- entropy.rel %>% 
  group_by(gene_abbr, row) %>% 
  summarise(pmin = min(all_position), pmax = max(all_position)) %>% 
  ungroup() %>% 
  filter(complete.cases(.)) %>% 
  mutate(ymin = -1.1, ymax = 1.1)

# Create custom breaks for pretty y axis
breaks <- labeling::extended(0.25, 1, 4)
breaks_pos <- c(-1 * (rev(breaks) + 0.05), breaks + 0.05)
breaks <- as.character(c(rev(breaks), breaks))

# Create data frame for text in plot
text_frame <- plot_data %>% 
  group_by(row) %>% 
  summarise(x = min(rel_start)) %>% 
  mutate(y = 0.9, label = "SARS2 Pos.") %>% 
  rbind(., mutate(., y = -0.9, label = "SARS2 Neg."))

# Make plot
sars2.proteome.plots <- plot_data %>%
  split(., .$ig_type) %>% 
  map2(., names(.), ~{
    # Split microarray data
    plot_data_n <- filter(.x, !Response)
    plot_data_p <- filter(.x, Response)
    
    #Plot start
    ggplot() +  #Make empty plot
      geom_rect(data = prot_rect, # Add protein box background
                aes(xmin = pmin, xmax = pmax, ymin = ymin, ymax = ymax, fill = gene_abbr), alpha = 0.6, inherit.aes = F) +
      scale_fill_brewer(palette = "Set3", na.translate = F, 
                        guide = guide_legend(nrow=1,byrow=TRUE,title = "Protein", 
                                             title.position = "top", title.hjust = 0.5, 
                                             keywidth = 0.5, keyheight = 0.5)) + 
      new_scale_fill() +
      geom_linerange(data = entropy.rel, aes(x = all_position, ymin = ymin, ymax = entropy_scale)) + # Add entropy
      geom_rect(data = plot_data_n, aes(xmin = rel_start, xmax = rel_end, # Add negative responses
                                        ymin = ymin, ymax = plot_signal),
                alpha = 0.3, inherit.aes = F, fill = "grey50") +
      geom_rect(data = plot_data_p, aes(xmin = rel_start, xmax = rel_end, # Add positive responses
                                      ymin = ymin, ymax = plot_signal), 
                alpha = 0.3, inherit.aes = F, fill = "dodgerblue") +
      geom_text(data = text_frame, # Add text to plot
                aes(x = x, y = y, label = label),
                inherit.aes = F, hjust = -0.15, size = text_size * (5/14)) +
      scale_x_continuous(expand = c(0, 0)) +
      scale_y_continuous(limits = c(-1.1, 1.1), breaks = c(breaks_pos), 
                         labels = c(breaks), 
                         expand = c(0,0),
                         sec.axis = sec_axis(~ . * 1, breaks = c(breaks_pos),
                                             labels = c(breaks), name = "Relative Shannon Entropy")) +
      facet_wrap(~row, scales = "free_x", ncol = 1) +
      # labs(x = "AA Position", y = "Scaled Signal", title = .y) +
      labs(x = "Proteome Position", y = "Scaled Signal") +
      theme_pubclean(base_size = text_size) +
      theme(axis.title = element_text(face = "bold"),
            legend.title = element_text(face = "bold", size = text_size),
            legend.position = "top",
            legend.direction = "horizontal",
            panel.grid.major.x = element_line(),
            strip.background = element_blank(),
            strip.text.x = element_blank())
  })

```

Write Figure 5 and Supplementary figure 2.
```{r print-proteome-plots, message=FALSE, warning=FALSE}
# Print IgG plot
ggsave("./images/publication/figure5.svg", sars2.proteome.plots$IgG,
       width = width2, height = width2, units = "mm")

# Print IgA plot
ggsave("./images/publication/supplementary_figure2.svg", sars2.proteome.plots$IgA,
       width = width2, height = width2, units = "mm")

# Clear space
rm(list = c(ls(pattern = "sars2|rel|prot|row|plot|text_frame|aligns|break|end")))
```

### Alignment of high-fidelity peptides
Generate the response regions from the individual response peptides overlapping in their parent protein sequences. Group response regions together if they share at least 1 common response peptide. Generate multiple alignment of response regions using guide trees generated for each grouping formed as described above. Write Table 3, Supplementary table 3, and Supplementary table 4.
```{r peptide-alignments, message=FALSE, warning=FALSE}
# Filter for responses and merge peptide intervals within protein and group
intersect_v <- Vectorize("intersect", vectorize.args = "y")

# Combine overlapping response peptides into a response region, then find response regions with matching peptides
response_intervals <- data.analysed %>% 
  filter(Response) %>% 
  filter(str_detect(prot_name, "R1A_", T)) %>% 
  unite(., col = "ID", org, id, prot_name, ig_type, patient_group, remove = F, sep = "#") %>% 
  split(., .$ID) %>% 
  keep(., ~nrow(.x) > 0) %>% 
  compact(.) %>% 
  map(.,~{
    q <- .x %>% 
      dplyr::select(start, end, scale_signal) %>% 
      as_iranges(.) %>% 
      reduce_ranges(AUC = sum(scale_signal), N = length(scale_signal))
        
    s <- .x %>% 
      dplyr::select(start, end, "peptides" = coresequence) %>% 
      as_iranges(.)
    
    mergeByOverlaps(s,q) %>% 
      as.data.frame(.) %>% 
      dplyr::select(starts_with("q"), s.peptides) %>% 
      rename_all(., ~str_remove(.,"^[qs]\\.")) %>%
      mutate(prot_name = unique(.x$prot_name)) %>% 
      mutate_if(is.list, ~unique(unlist(.))) %>% 
      rowwise(.) %>%
      mutate(prot_seq = as.character(extractAt(fasta[[prot_name]], IRanges(start,end)))) %>%
      ungroup(.) %>%
      group_by(prot_seq) %>%
      summarise_all(., ~list(unique(.))) %>%
      mutate_at(vars(-peptides), unlist)
  }) %>% 
  rbindlist(., idcol = "ID") %>%
  unite(.,col = "ID", ID, start, end, sep = "#") %>% 
  rowwise(.) %>% 
  mutate(matches = list(.$ID[
    lengths(intersect_v(peptides, .$peptides))>0
  ]))

# Create alignments of matching response intervals
response_alignments <- response_intervals$matches %>% 
  .[!duplicated(.)] %>% 
  map(., ~{
    temp <- response_intervals %>% 
      filter(ID %in% .x)
    
    seqs <- temp$prot_seq
    names(seqs) <- temp$ID
    if(length(seqs) > 1){
      out <- AlignSeqs(AAStringSet(seqs, use.names = T), verbose = F)
    } else {
      out <- AAStringSet(seqs, use.names = T)
    }
    as.data.frame(out) %>% 
      rownames_to_column("ID")
    }) %>% 
  rbindlist(., idcol = "align_id") %>% 
  separate(., ID, 
           into =  c("org", "id", "prot_name", "ig_type", "patient_group","start","end"), 
           sep = "#") %>% 
  group_split(align_id) %>% 
  map(., ~ .x %>% arrange(desc(str_count(x, "[^-]")))) %>% 
  rbindlist(.)

# Add gene_abbr to alignments
response_alignments <- response_alignments %>% 
  left_join(., distinct(complete.map, prot_name, gene_abbr)) %>% 
  mutate(start = as.integer(start), end = as.integer(end))

# Add omicron mutations and mean entropy to SARS-CoV-2 responses
mut_ent_map <- response_alignments %>% 
  filter(org == "SARS-CoV-2") %>% 
  distinct(gene_abbr) %>% 
  unlist(.) %>% 
  map(., ~{
    ent <- entropy_x %>% filter(gene_abbr == .x) %>% 
      mutate(start = position, width = 1) %>% 
      dplyr::select(start, width, position_entropy) %>% 
      as_iranges(.)
    
    # mut <- variant_mutations %>% filter(Protein == .x) %>% 
    #   mutate(start = as.integer(pstart), end = as.integer(pend)) %>% 
    #   dplyr::select(start, end, Mutation, Variants) %>% 
    #   as_iranges(.)
    
    als <- response_alignments %>% 
      filter(org == "SARS-CoV-2") %>% 
      filter(gene_abbr == .x) %>% 
      mutate(start = as.integer(start), end = as.integer(end)) %>% 
      as_iranges(.)
    
    # temp.mut <- mergeByOverlaps(als, mut) %>% 
    #   as.data.frame(.) %>% 
    #   dplyr::rename("start" = "als.start", "end" = "als.end") %>% 
    #   select_at(vars(-contains("."))) %>% 
    #   dplyr::select(-Protein)
    
    temp.ent <- mergeByOverlaps(als, ent) %>% 
      as.data.frame(.) %>% 
      dplyr::rename("start" = "als.start", "end" = "als.end") %>% 
      select_at(vars(-contains(".")))
    
    # full_join(temp.mut, temp.ent, intersect(names(temp.mut), names(temp.ent))) %>% 
    temp.ent %>% 
      group_by_at(vars(-position_entropy)) %>% 
      summarise_all(list(Mean = mean, SD = sd))
  }) %>% 
  rbindlist(.)

# Add mutation and entropy info
response_alignments <- left_join(response_alignments, 
                                 mut_ent_map, 
                                 intersect(names(response_alignments), 
                                           names(mut_ent_map))) %>% 
  dplyr::select(-c("start", "end", "x"),start,end,x, -prot_name) %>% 
  # group_by_at(vars(-Mutation, -Variants)) %>% 
  group_by_all() %>% 
  summarise_all(~paste(., sep = "; ", collapse = "; ")) %>% 
  # dplyr::select(union(c("align_id", "org", "id", "gene_abbr", "ig_type", "patient_group", "Mutation", "Variants"), names(.))) %>% 
  dplyr::select(union(c("align_id", "org", "id", "gene_abbr", "ig_type", "patient_group"), names(.))) %>% 
  as.data.table(.)

# # Write individual tables
# # SARS-CoV-2 alignments
# response_alignments %>%
#   .[,if(any(org == "SARS-CoV-2")) .SD, by = "align_id"] %>%
#     .[, arrange(.SD, desc(str_count(x, "[A-Z]"))), by = "align_id"] %>%
#   mutate_at(vars(Mutation, Variants), ~ifelse(. == "NA", NA, .)) %>%
#   fwrite(., "./images/publication/sars-cov-2_all_aligns.txt", sep = "\t", dec = ",")
# 
# # All Coronaviridae alignments
# corona_counts <- response_alignments %>%
#   .[,if(all(!org %in% c("HCMV"))) .SD, by = "align_id"] %>%
#   .[, arrange(.SD, desc(str_count(x, "[A-Z]"))), by = "align_id"] %>%
#   mutate_at(vars(Mutation, Variants), ~ifelse(. == "NA", NA, .)) %>%
#   fwrite(., "./images/publication/coronaviridae_aligns.txt", dec = ",", sep = "\t")
# 
# # HCMV alignments
# response_alignments %>%
#   .[,if(all(org == "HCMV")) .SD, by = "align_id"] %>%
#   .[, arrange(.SD, desc(str_count(x, "[A-Z]"))), by = "align_id"] %>%
#   dplyr::select(-c("Mutation", "Variants", "Mean", "SD")) %>%
#   fwrite(., "./images/publication/hcmv_aligns.txt", sep = "\t", dec = ",")


```

### Difference in relative Shannon entropy
Estimate 95% confidence interval of the differences in mean relative Shannon entropy between the SARS-CoV-2 protein positions encompassed by high-fidelity antibody binding peptides and the positions with low-fidelity antibody binding.

```{r annotate-positive-positions}
# Flag SARS-CoV-2 position in entropy data set overlapping areas with high-fidelity peptides
sars2_intervals <- response_alignments %>% 
  filter(org == "SARS-CoV-2") %>% 
  distinct(gene_abbr, ig_type, patient_group, start, end)

# Add serum pool and Ig-type to the entropy_x positions overlapping high-fidelity peptides
entropy_mapped <- unlist(distinct(sars2_intervals, gene_abbr)) %>% 
  map(., ~{
    rec <- filter(sars2_intervals, gene_abbr == .x) %>% 
      dplyr::select(-gene_abbr) %>% 
      as_iranges(.)
    
    ent <- filter(entropy_x, gene_abbr == .x) %>% 
      mutate(start = position, end = position) %>% 
      as_iranges(.)
    
    join_overlap_left(ent, rec) %>% 
      as.data.frame(.)
  }) %>% 
  rbindlist(.)

# Combine entropy_mapped with entropy
entropy_mapped <- left_join(entropy_x, entropy_mapped, 
                            by = intersect(names(entropy_x), 
                                           names(entropy_mapped))) %>% 
  # mutate(gene_abbr = factor(gene_abbr, levels = protein_order)) %>% 
  distinct_all(.) %>% 
  mutate(entropy_rel = position_entropy / log2(21),
         ig_type = replace(ig_type, list = is.na(ig_type), "None"),
         patient_group = replace(patient_group, list = is.na(patient_group), "None"))

```

```{r entropy-bootstrap-bca, message=FALSE, warning=FALSE}
# Split entropy_mapped into antibody targets and none-targets
entropy_mapped_split <- entropy_mapped %>% 
  split(.,list(.$ig_type, .$patient_group), drop = T, sep = "_")

# Function for boot to calculate mean differences
meanDiff <- function(x, i, a_idx, b_idx){
  mean(x[i[a_idx]]) - mean(x[i[b_idx]])
}

# Number of bootstrap samples to draw
boot_n <- 10000

# Run the bootstrap confidence interval estimation
boot_ci <- map(combn(names(entropy_mapped_split), m = 2, simplify = F), function(group){
    # Get data for sets A and B
    A <- entropy_mapped_split[[group[1]]]
    B <- entropy_mapped_split[[group[2]]]
    
    # Combine the relative entropy into one vector
    ent <- c(A$entropy_rel, B$entropy_rel)
    
    # Create vector of the indeces of each group in the entropy vector
    id <- as.factor(c(rep(group[1], nrow(A)), rep(group[2], nrow(B))))
    
    # Make the "boot" object
    boot_obj <- boot(ent, statistic = meanDiff, strata = id, R = boot_n,
                     a_idx = id == group[1], b_idx = id == group[2],
                     parallel = "multicore", ncpus = 8)
    
    # Estimate confidence interval
    result <- boot.ci(boot_obj, type = "perc", conf = 0.99)
    
    data.frame(A = group[1], B = group[2], 
               A_n = nrow(A), B_n = nrow(B),
              `1%` = result$percent[,4],
              `99%` = result$percent[,5])
})

boot_ci %>% rbindlist(.)


```

